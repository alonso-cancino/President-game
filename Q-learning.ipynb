{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d4bc26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym import spaces\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from collections import deque\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a03e8104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observations are of the form\n",
    "\n",
    "# (agents hand, played cards, number of cards of enemies, stack quantity, stack nu, active player, last player)\n",
    "\n",
    "# agent hand and played cards are encoded as (n° of 0's, n° of 1's, ..., n° of 9's)\n",
    "\n",
    "def observation_space(n_of_players):\n",
    "    \n",
    "    size_lst = []\n",
    "    \n",
    "    for _ in range(20):\n",
    "        size_lst.append(5)\n",
    "    for _ in range(n_of_players-1):\n",
    "        size_lst.append((40/n_of_players)+1)\n",
    "        \n",
    "    size_lst.append(5)\n",
    "    size_lst.append(10)\n",
    "    \n",
    "    for _ in range(2):\n",
    "        size_lst.append(n_of_players)\n",
    "    \n",
    "    size_vec = np.array(size_lst)\n",
    "    \n",
    "    return spaces.MultiDiscrete(size_vec,dtype='uint8')\n",
    "\n",
    "def action_space():\n",
    "    \n",
    "    return spaces.MultiDiscrete((11,5),dtype='uint8')\n",
    "\n",
    "def deal(n_of_players):\n",
    "    \n",
    "    players_data = []\n",
    "    deck = []\n",
    "    available_indices =list(range(40))\n",
    "    active_player = None\n",
    "        \n",
    "    for pinta in ['O','B','C','E']:\n",
    "        for n in range(10):\n",
    "            deck.append(str(n)+pinta)\n",
    "        \n",
    "    for player in range(n_of_players):\n",
    "\n",
    "        sample = random.sample(available_indices,int(40/n_of_players))\n",
    "        players_data.append([deck[ind] for ind in sample])\n",
    "        available_indices = list(set(available_indices) - set(sample))\n",
    "    \n",
    "    if active_player == None:\n",
    "        for player in range(n_of_players):\n",
    "            if '0O' in players_data[player]:\n",
    "                active_player = player\n",
    "\n",
    "    return players_data, active_player\n",
    "\n",
    "\n",
    "# Inputs to encode_players are:\n",
    "# players_data : info on players hands\n",
    "\n",
    "\n",
    "\n",
    "def encode_players_hand(game_data,player):\n",
    "    \n",
    "    players_hand = [0]*10\n",
    "    \n",
    "    for card in game_data[player]:\n",
    "        \n",
    "        players_hand[int(card[0])] +=1\n",
    "        \n",
    "    return players_hand\n",
    "    \n",
    "\n",
    "\n",
    "def encode_players_data(players_data,history,stack,agent,active_player=None,last_player=None):\n",
    "    \n",
    "    agent_hand = players_data[0]\n",
    "    \n",
    "    agent_cards = [0]*10\n",
    "    \n",
    "    enemy_handsize = []\n",
    "    \n",
    "    encoded_history = [0]*10\n",
    "    \n",
    "    if stack != []:\n",
    "        \n",
    "        encoded_stack = [len(stack),int(stack[0][0])]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        encoded_stack = [0, None]\n",
    "        \n",
    "    if active_player == None:\n",
    "    \n",
    "        play_status = [players_data[1],last_player]\n",
    "    \n",
    "    for card in agent_hand:\n",
    "        \n",
    "        agent_cards[int(card[0])] += 1\n",
    "        \n",
    "    n_p = len(players_data[0])\n",
    "    \n",
    "    for enemy in range(n_p):\n",
    "        \n",
    "        if enemy != agent:\n",
    "            \n",
    "            enemy_handsize += [len(players_data[enemy])]\n",
    "            \n",
    "    for card in history:\n",
    "        \n",
    "        encoded_history[int(card[0])]+=1\n",
    "    \n",
    "    encoded_data = agent_cards + encoded_history + enemy_handsize + encoded_stack + play_status\n",
    "    \n",
    "    return encoded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cde33553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll assume (and construct) the class such that the player\n",
    "# supposed to play is the active player.\n",
    "\n",
    "def possible_plays(state):\n",
    "\n",
    "        curr_quantity = state[23] # Number of card(s) already in play\n",
    "        curr_number = state[24] # Value of the cards in play\n",
    "        \n",
    "        active_player = state[25] # Who has the option to play\n",
    "        last_player = state[26] # Who was the last to play\n",
    "        \n",
    "        pos_plays = ['']\n",
    "        \n",
    "        if last_player == None:\n",
    "            \n",
    "            pos_plays = []\n",
    "            \n",
    "            for number in range(1):\n",
    "                \n",
    "                for quantity in range(1,state[number]+1):\n",
    "                    \n",
    "                    pos_plays.append([quantity,number])\n",
    "                    \n",
    "        elif (active_player == last_player):\n",
    "                \n",
    "            for number in range(10):\n",
    "                \n",
    "                if state[number] >= 1:\n",
    "\n",
    "                    for quantity in range(1,state[number]+1):\n",
    "\n",
    "                        pos_plays.append([quantity,number])\n",
    "\n",
    "        \n",
    "        elif (active_player != last_player) and curr_number != 9:\n",
    "            \n",
    "            for number in range(curr_number,10):\n",
    "                \n",
    "                if state[number] >= 1:\n",
    "                \n",
    "                    for quantity in range(1,state[number]+1):\n",
    "                        \n",
    "                        pos_plays.append([quantity,number])\n",
    "        \n",
    "        return pos_plays\n",
    "\n",
    "    \n",
    "def game_start(n_players,seed=42):\n",
    "    \n",
    "    random.seed(seed)\n",
    "    \n",
    "    dealt_hands = deal(n_players)\n",
    "    \n",
    "    print(dealt_hands)\n",
    "    \n",
    "    overall_data = []\n",
    "    \n",
    "    print(dealt_hands[0][0])\n",
    "    \n",
    "    agent_state = encode_players_data(dealt_hands,[],[],0)\n",
    "    \n",
    "    return agent_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "024636d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 2, 0, 0, 2, 2, 2, 1, 0], [1, 2, 1, 1, 0, 0, 1, 2, 0, 2], [2, 0, 1, 1, 2, 0, 1, 0, 1, 2], [0, 2, 0, 2, 2, 2, 0, 0, 2, 0]] None None None 0 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[[0, 0, 2, 0, 0, 2, 2, 2, 1, 0], [1, 2, 1, 1, 0, 0, 1, 2, 0, 2], [2, 0, 1, 1, 2, 0, 1, 0, 1, 2], [0, 2, 0, 2, 2, 2, 0, 0, 2, 0]] 1 0 0 1 [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def deal(n_of_players):\n",
    "    \n",
    "    players_data = []\n",
    "    deck = []\n",
    "    available_indices =list(range(40))\n",
    "    active_player = None\n",
    "        \n",
    "    for pinta in ['O','B','C','E']:\n",
    "        for n in range(10):\n",
    "            deck.append(str(n)+pinta)\n",
    "        \n",
    "    for player in range(n_of_players):\n",
    "\n",
    "        sample = random.sample(available_indices,int(40/n_of_players))\n",
    "        players_data.append([deck[ind] for ind in sample])\n",
    "        available_indices = list(set(available_indices) - set(sample))\n",
    "    \n",
    "    if active_player == None:\n",
    "        for player in range(n_of_players):\n",
    "            if '0O' in players_data[player]:\n",
    "                active_player = player\n",
    "\n",
    "    return players_data, active_player\n",
    "\n",
    "\n",
    "\n",
    "def encode_players_hand(game_data,player):\n",
    "    \n",
    "    players_hand = [0]*10\n",
    "    \n",
    "    for card in game_data[player]:\n",
    "        \n",
    "        players_hand[int(card[0])] +=1\n",
    "        \n",
    "    return players_hand\n",
    "\n",
    "\n",
    "\n",
    "def start_game(n_players,seed = 1234):\n",
    "    \n",
    "    random.seed(seed)\n",
    "    \n",
    "    dealt_hands, starting_player = deal(n_players)\n",
    "    hands_data = [[]]*n_players\n",
    "    \n",
    "    for player in range(n_players):\n",
    "        hands_data[player] = encode_players_hand(dealt_hands,player)\n",
    "    \n",
    "    history = [0]*10\n",
    "    last_player = None\n",
    "    stack_quantity = None\n",
    "    stack_value = None\n",
    "    \n",
    "    return hands_data, history ,starting_player, last_player, stack_quantity, stack_value\n",
    "\n",
    "\n",
    "def pos_plays(hands_data,stack_quantity,stack_value, last_player,player):\n",
    "    \n",
    "    pass_turn = ['']\n",
    "    av_plays = []\n",
    "    \n",
    "    if (stack_quantity == None) and (last_player == None):\n",
    "        \n",
    "        h = hands_data[player]\n",
    "        \n",
    "        for amount in range(1,h[0]+1):\n",
    "        \n",
    "            av_plays.append([amount,0])\n",
    "            \n",
    "        return av_plays\n",
    "    \n",
    "    elif stack_quantity == None:\n",
    "        \n",
    "        h = hands_data[player]\n",
    "        \n",
    "        for card in h:\n",
    "            \n",
    "            for amount in range(1,h[card]+1):\n",
    "                \n",
    "                av_plays.append([amount,card])\n",
    "                \n",
    "        return av_plays\n",
    "        \n",
    "    elif stack_quantity != None:\n",
    "        \n",
    "        if stack_value == 9:\n",
    "            \n",
    "            return pass_turn\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            for card in range(stack_value,10):\n",
    "                \n",
    "                if h[card]>=stack_quantity:\n",
    "                    \n",
    "                    for amount in range(1,h[card]+1):\n",
    "                        \n",
    "                        av_plays.append([amount,card])\n",
    "            \n",
    "            return pass_turn + av_plays\n",
    "\n",
    "        \n",
    "def play_selection(hands_data, history, active_player, last_player, stack_quantity, stack_value, play):\n",
    "    \n",
    "    possible_plays = pos_plays(hands_data,stack_quantity,stack_value,last_player,active_player)\n",
    "     \n",
    "    assert play in range(len(possible_plays))\n",
    "    \n",
    "    stack_quantity = possible_plays[play][0]\n",
    "    stack_value = possible_plays[play][1]\n",
    "    \n",
    "    hands_data[active_player][stack_value] = hands_data[active_player][stack_value] - stack_quantity\n",
    "    \n",
    "    last_player = active_player\n",
    "    \n",
    "    active_player = (active_player + 1)%len(hands_data)\n",
    "    \n",
    "    history[stack_value] = history[stack_value] + stack_quantity\n",
    "    \n",
    "    return hands_data, history, active_player, last_player, stack_quantity, stack_value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ejemplo\n",
    "hands_data, history ,starting_player, last_player, stack_quantity, stack_value = start_game(4)\n",
    "print(hands_data, stack_quantity, stack_value, last_player, starting_player, history)\n",
    "pos_plays(hands_data,stack_quantity,stack_value,last_player,starting_player)\n",
    "hands_data, history, active_player,last_player, stack_quantity, stack_value = play_selection(hands_data, history, starting_player, last_player, stack_quantity, stack_value, 0)\n",
    "print(hands_data, stack_quantity, stack_value, last_player, active_player, history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0ac3d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class culo(gym.Env):\n",
    "    \n",
    "    def __init__(self,n_p):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_p = n_p\n",
    "        self.action_space = action_space(self.n_p)\n",
    "        self.observation_space = observation_space(self.n_p)\n",
    "        \n",
    "    def reset(self):\n",
    "        \n",
    "        self.placements = []\n",
    "        players_data = deal(self.n_p)\n",
    "        self.hands, self.active_player = encode_players_hands()\n",
    "        \n",
    "        \n",
    "    def step(self,action):\n",
    "        \n",
    "        new_state, reward, done = play_selection(hands_data, history, active_player, last_player, stack_quantity, stack_value, action)\n",
    "        \n",
    "        return new_state, reward, done\n",
    "                \n",
    "    def render(self):\n",
    "        \n",
    "        print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "2a207130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Activation, Flatten\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "#...\n",
    "# Own Tensorboard class\n",
    "class ModifiedTensorBoard(TensorBoard):\n",
    "\n",
    "    # Overriding init to set initial step and writer (we want one log file for all .fit() calls)\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.step = 1\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir)\n",
    "\n",
    "    # Overriding this method to stop creating default log writer\n",
    "    def set_model(self, model):\n",
    "        pass\n",
    "\n",
    "    # Overrided, saves logs with our step number\n",
    "    # (otherwise every .fit() will start writing from 0th step)\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.update_stats(**logs)\n",
    "\n",
    "    # Overrided\n",
    "    # We train for one batch only, no need to save anything at epoch end\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        pass\n",
    "\n",
    "    # Overrided, so won't close writer\n",
    "    def on_train_end(self, _):\n",
    "        pass\n",
    "\n",
    "    # Custom method for saving own metrics\n",
    "    # Creates writer, writes custom metrics and closes writer\n",
    "    def update_stats(self, **stats):\n",
    "        self._write_logs(stats, self.step)\n",
    "\n",
    "\n",
    "REPLAY_MEMORY_SIZE = 50000\n",
    "MODEL_NAME = \"256x2\"\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # main model (this gets trained every step)\n",
    "        self.model = self.create_model()\n",
    "        \n",
    "        # target model (this is what we .predict against every step)\n",
    "        self.target_model = self.create_model()\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "        self.replay_memory = self.deque(maxlen = REPLAY_MEMORY_SIZE)\n",
    "        \n",
    "        self.tensorboard = ModifiedTensorBoard(logs_dir = f\"logs/{MODEL_NAME}-{int(time.time())}\")\n",
    "        \n",
    "        self.target_update_counter = 0\n",
    "        \n",
    "    def create_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(256,(3,3),input_shape = env.OBSERVATION_SPACE_VALUES))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(2,2))\n",
    "        model.add(Dropout(0.2))\n",
    "            \n",
    "        model.add(Conv2D(256,(3,3)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(2,2))\n",
    "        model.add(Dropout(0.2))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(64))\n",
    "        \n",
    "        model.add(Dense(env.ACTION_SPACE_SIZE,activation = \"linear\"))\n",
    "        model.compile(loss=\"mse\",optimizer = Adam(lr=0.001),metrics =['accuracy'])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def update_replay_memory(self,transition):\n",
    "        self.replay_memory.append(transition)\n",
    "    \n",
    "    def get_qs(self, state, step):\n",
    "        return self.model_predict(np.array(state).reshape(-1,*state.shape)/255)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a179e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
